#!/bin/bash


LLAMA2_7B=/mnt/sdb/zhanglongteng/sdd/zhanglongteng/Llama-2-7b-chat-hf
LLAMA3_8B=/mnt/sdb/zhanglongteng/sdd/zhanglongteng/Meta-Llama-3-8B-Instruct

CUDA_VISIBLE_DEVICES=0,1 DS_SKIP_CUDA_CHECK=1 accelerate launch --main_process_port 31000 finetune.py --dataset_name_or_path mmlu --output_dir validate --logging_strategy steps --logging_steps 1 --save_strategy epoch --dataloader_num_workers 32 --remove_unused_columns False --do_train --ddp_find_unused_parameters False --overwrite_output_dir --bf16 True --tf32 True --max_steps -1 --hard_padding False --save_total_limit 3 --num_train_epochs 3 --learning_rate 5e-5 --per_device_train_batch_size 4 --source_max_len 896 --target_max_len 128 --model_name_or_path $LLAMA3_8B --flash_attn True --report_to wandb --gradient_checkpointing False --peft lora --lora_rank 64 --lora_scale 2.0 --init_lora_weights gaussian --quant True --quant_method hqq4 --gradient_accumulation_steps 2

exit 0

# CUDA_VISIBLE_DEVICES=4,5,6,7 DS_SKIP_CUDA_CHECK=1 accelerate launch --main_process_port 31000 finetune.py --dataset_name_or_path mmlu --output_dir /mnt/sdb/zhanglongteng/sdd/zhanglongteng/finetune/Meta-Llama-3-8B-Instruct/Meta-Llama-3-8B-Instruct.mmlu.hqq4.r64.scale2.lr5e-5 --logging_strategy steps --logging_steps 1 --save_strategy epoch --dataloader_num_workers 32 --remove_unused_columns False --do_train --ddp_find_unused_parameters False --overwrite_output_dir --bf16 True --tf32 True --max_steps -1 --hard_padding False --save_total_limit 3 --num_train_epochs 3 --learning_rate 5e-5 --per_device_train_batch_size 4 --source_max_len 896 --target_max_len 128 --model_name_or_path $LLAMA3_8B --flash_attn True --report_to wandb --gradient_checkpointing False --peft lora --lora_rank 64 --lora_scale 2.0 --init_lora_weights gaussian --quant True --quant_method hqq4 --gradient_accumulation_steps 2

CUDA_VISIBLE_DEVICES=4,5,6,7 DS_SKIP_CUDA_CHECK=1 accelerate launch --main_process_port 31000 finetune.py --dataset_name_or_path mmlu --output_dir /mnt/sdb/zhanglongteng/sdd/zhanglongteng/finetune/Meta-Llama-3-8B-Instruct/Meta-Llama-3-8B-Instruct.mmlu.hqq4.r64.scale2.lr7e-5 --logging_strategy steps --logging_steps 1 --save_strategy epoch --dataloader_num_workers 32 --remove_unused_columns False --do_train --ddp_find_unused_parameters False --overwrite_output_dir --bf16 True --tf32 True --max_steps -1 --hard_padding False --save_total_limit 3 --num_train_epochs 3 --learning_rate 7e-5 --per_device_train_batch_size 4 --source_max_len 896 --target_max_len 128 --model_name_or_path $LLAMA3_8B --flash_attn True --report_to wandb --gradient_checkpointing False --peft lora --lora_rank 64 --lora_scale 2.0 --init_lora_weights gaussian --quant True --quant_method hqq4 --gradient_accumulation_steps 2

CUDA_VISIBLE_DEVICES=4,5,6,7 DS_SKIP_CUDA_CHECK=1 accelerate launch --main_process_port 31000 finetune.py --dataset_name_or_path mmlu --output_dir /mnt/sdb/zhanglongteng/sdd/zhanglongteng/finetune/Meta-Llama-3-8B-Instruct/Meta-Llama-3-8B-Instruct.mmlu.hqq4.r64.scale2.lr9e-5 --logging_strategy steps --logging_steps 1 --save_strategy epoch --dataloader_num_workers 32 --remove_unused_columns False --do_train --ddp_find_unused_parameters False --overwrite_output_dir --bf16 True --tf32 True --max_steps -1 --hard_padding False --save_total_limit 3 --num_train_epochs 3 --learning_rate 9e-5 --per_device_train_batch_size 4 --source_max_len 896 --target_max_len 128 --model_name_or_path $LLAMA3_8B --flash_attn True --report_to wandb --gradient_checkpointing False --peft lora --lora_rank 64 --lora_scale 2.0 --init_lora_weights gaussian --quant True --quant_method hqq4 --gradient_accumulation_steps 2

# CUDA_VISIBLE_DEVICES=4,5,6,7 DS_SKIP_CUDA_CHECK=1 accelerate launch --main_process_port 31000 finetune.py --dataset_name_or_path mmlu --output_dir /mnt/sdb/zhanglongteng/sdd/zhanglongteng/finetune/Meta-Llama-3-8B-Instruct/Meta-Llama-3-8B-Instruct.mmlu.hqq4.r64.scale16.lr5e-5 --logging_strategy steps --logging_steps 1 --save_strategy epoch --dataloader_num_workers 32 --remove_unused_columns False --do_train --ddp_find_unused_parameters False --overwrite_output_dir --bf16 True --tf32 True --max_steps -1 --hard_padding False --save_total_limit 3 --num_train_epochs 3 --learning_rate 5e-5 --per_device_train_batch_size 4 --source_max_len 896 --target_max_len 128 --model_name_or_path $LLAMA3_8B --flash_attn True --report_to wandb --gradient_checkpointing False --peft lora --lora_rank 64 --lora_scale 16.0 --init_lora_weights gaussian --quant True --quant_method hqq4 --gradient_accumulation_steps 2

# CUDA_VISIBLE_DEVICES=4,5,6,7 DS_SKIP_CUDA_CHECK=1 accelerate launch --main_process_port 31000 finetune.py --dataset_name_or_path mmlu --output_dir /mnt/sdb/zhanglongteng/sdd/zhanglongteng/finetune/Meta-Llama-3-8B-Instruct/Meta-Llama-3-8B-Instruct.mmlu.hqq4.r64.scale2.lr7e-5 --logging_strategy steps --logging_steps 1 --save_strategy epoch --dataloader_num_workers 32 --remove_unused_columns False --do_train --ddp_find_unused_parameters False --overwrite_output_dir --bf16 True --tf32 True --max_steps -1 --hard_padding False --save_total_limit 3 --num_train_epochs 3 --learning_rate 7e-5 --per_device_train_batch_size 4 --source_max_len 896 --target_max_len 128 --model_name_or_path $LLAMA3_8B --flash_attn True --report_to wandb --gradient_checkpointing False --peft lora --lora_rank 64 --lora_scale 16.0 --init_lora_weights gaussian --quant True --quant_method hqq4 --gradient_accumulation_steps 2

# CUDA_VISIBLE_DEVICES=4,5,6,7 DS_SKIP_CUDA_CHECK=1 accelerate launch --main_process_port 31000 finetune.py --dataset_name_or_path mmlu --output_dir /mnt/sdb/zhanglongteng/sdd/zhanglongteng/finetune/Meta-Llama-3-8B-Instruct/Meta-Llama-3-8B-Instruct.mmlu.hqq4.r64.scale2.lr9e-5 --logging_strategy steps --logging_steps 1 --save_strategy epoch --dataloader_num_workers 32 --remove_unused_columns False --do_train --ddp_find_unused_parameters False --overwrite_output_dir --bf16 True --tf32 True --max_steps -1 --hard_padding False --save_total_limit 3 --num_train_epochs 3 --learning_rate 9e-5 --per_device_train_batch_size 4 --source_max_len 896 --target_max_len 128 --model_name_or_path $LLAMA3_8B --flash_attn True --report_to wandb --gradient_checkpointing False --peft lora --lora_rank 64 --lora_scale 16.0 --init_lora_weights gaussian --quant True --quant_method hqq4 --gradient_accumulation_steps 2



# CUDA_VISIBLE_DEVICES=4,5,6,7 DS_SKIP_CUDA_CHECK=1 accelerate launch --main_process_port 31000 finetune.py --dataset_name_or_path mmlu --output_dir /mnt/sdb/zhanglongteng/sdd/zhanglongteng/finetune/Meta-Llama-3-8B-Instruct/Meta-Llama-3-8B-Instruct.mmlu.hqq4.r16.scale2.lr5e-5 --logging_strategy steps --logging_steps 1 --save_strategy epoch --dataloader_num_workers 32 --remove_unused_columns False --do_train --ddp_find_unused_parameters False --overwrite_output_dir --bf16 True --tf32 True --max_steps -1 --hard_padding False --save_total_limit 3 --num_train_epochs 3 --learning_rate 5e-5 --per_device_train_batch_size 4 --source_max_len 896 --target_max_len 128 --model_name_or_path $LLAMA3_8B --flash_attn True --report_to wandb --gradient_checkpointing False --peft lora --lora_rank 16 --lora_scale 2.0 --init_lora_weights gaussian --quant True --quant_method hqq4 --gradient_accumulation_steps 2

# CUDA_VISIBLE_DEVICES=4,5,6,7 DS_SKIP_CUDA_CHECK=1 accelerate launch --main_process_port 31000 finetune.py --dataset_name_or_path mmlu --output_dir /mnt/sdb/zhanglongteng/sdd/zhanglongteng/finetune/Meta-Llama-3-8B-Instruct/Meta-Llama-3-8B-Instruct.mmlu.hqq4.r16.scale2.lr7e-5 --logging_strategy steps --logging_steps 1 --save_strategy epoch --dataloader_num_workers 32 --remove_unused_columns False --do_train --ddp_find_unused_parameters False --overwrite_output_dir --bf16 True --tf32 True --max_steps -1 --hard_padding False --save_total_limit 3 --num_train_epochs 3 --learning_rate 7e-5 --per_device_train_batch_size 4 --source_max_len 896 --target_max_len 128 --model_name_or_path $LLAMA3_8B --flash_attn True --report_to wandb --gradient_checkpointing False --peft lora --lora_rank 16 --lora_scale 2.0 --init_lora_weights gaussian --quant True --quant_method hqq4 --gradient_accumulation_steps 2

# CUDA_VISIBLE_DEVICES=4,5,6,7 DS_SKIP_CUDA_CHECK=1 accelerate launch --main_process_port 31000 finetune.py --dataset_name_or_path mmlu --output_dir /mnt/sdb/zhanglongteng/sdd/zhanglongteng/finetune/Meta-Llama-3-8B-Instruct/Meta-Llama-3-8B-Instruct.mmlu.hqq4.r16.scale2.lr9e-5 --logging_strategy steps --logging_steps 1 --save_strategy epoch --dataloader_num_workers 32 --remove_unused_columns False --do_train --ddp_find_unused_parameters False --overwrite_output_dir --bf16 True --tf32 True --max_steps -1 --hard_padding False --save_total_limit 3 --num_train_epochs 3 --learning_rate 9e-5 --per_device_train_batch_size 4 --source_max_len 896 --target_max_len 128 --model_name_or_path $LLAMA3_8B --flash_attn True --report_to wandb --gradient_checkpointing False --peft lora --lora_rank 16 --lora_scale 2.0 --init_lora_weights gaussian --quant True --quant_method hqq4 --gradient_accumulation_steps 2

# CUDA_VISIBLE_DEVICES=4,5,6,7 DS_SKIP_CUDA_CHECK=1 accelerate launch --main_process_port 31000 finetune.py --dataset_name_or_path mmlu --output_dir /mnt/sdb/zhanglongteng/sdd/zhanglongteng/finetune/Meta-Llama-3-8B-Instruct/Meta-Llama-3-8B-Instruct.mmlu.hqq4.r16.scale8.lr5e-5 --logging_strategy steps --logging_steps 1 --save_strategy epoch --dataloader_num_workers 32 --remove_unused_columns False --do_train --ddp_find_unused_parameters False --overwrite_output_dir --bf16 True --tf32 True --max_steps -1 --hard_padding False --save_total_limit 3 --num_train_epochs 3 --learning_rate 5e-5 --per_device_train_batch_size 4 --source_max_len 896 --target_max_len 128 --model_name_or_path $LLAMA3_8B --flash_attn True --report_to wandb --gradient_checkpointing False --peft lora --lora_rank 16 --lora_scale 8.0 --init_lora_weights gaussian --quant True --quant_method hqq4 --gradient_accumulation_steps 2

# CUDA_VISIBLE_DEVICES=4,5,6,7 DS_SKIP_CUDA_CHECK=1 accelerate launch --main_process_port 31000 finetune.py --dataset_name_or_path mmlu --output_dir /mnt/sdb/zhanglongteng/sdd/zhanglongteng/finetune/Meta-Llama-3-8B-Instruct/Meta-Llama-3-8B-Instruct.mmlu.hqq4.r16.scale8.lr7e-5 --logging_strategy steps --logging_steps 1 --save_strategy epoch --dataloader_num_workers 32 --remove_unused_columns False --do_train --ddp_find_unused_parameters False --overwrite_output_dir --bf16 True --tf32 True --max_steps -1 --hard_padding False --save_total_limit 3 --num_train_epochs 3 --learning_rate 7e-5 --per_device_train_batch_size 4 --source_max_len 896 --target_max_len 128 --model_name_or_path $LLAMA3_8B --flash_attn True --report_to wandb --gradient_checkpointing False --peft lora --lora_rank 16 --lora_scale 8.0 --init_lora_weights gaussian --quant True --quant_method hqq4 --gradient_accumulation_steps 2

# CUDA_VISIBLE_DEVICES=4,5,6,7 DS_SKIP_CUDA_CHECK=1 accelerate launch --main_process_port 31000 finetune.py --dataset_name_or_path mmlu --output_dir /mnt/sdb/zhanglongteng/sdd/zhanglongteng/finetune/Meta-Llama-3-8B-Instruct/Meta-Llama-3-8B-Instruct.mmlu.hqq4.r16.scale8.lr9e-5 --logging_strategy steps --logging_steps 1 --save_strategy epoch --dataloader_num_workers 32 --remove_unused_columns False --do_train --ddp_find_unused_parameters False --overwrite_output_dir --bf16 True --tf32 True --max_steps -1 --hard_padding False --save_total_limit 3 --num_train_epochs 3 --learning_rate 9e-5 --per_device_train_batch_size 4 --source_max_len 896 --target_max_len 128 --model_name_or_path $LLAMA3_8B --flash_attn True --report_to wandb --gradient_checkpointing False --peft lora --lora_rank 16 --lora_scale 8.0 --init_lora_weights gaussian --quant True --quant_method hqq4 --gradient_accumulation_steps 2

./eval.sh
